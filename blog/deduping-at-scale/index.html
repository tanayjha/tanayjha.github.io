<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deduping at Scale | </title><meta name=keywords content><meta name=description content="Today I am going to talk about a project which I worked on in my organisation Sumo Logic.
We have this microservice which is used for collecting data from the cloud. One of the most prominent use case of that microservice is to collect data from customers S3 bucket.
I have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out here."><meta name=author content><link rel=canonical href=https://tanayjha.github.io/blog/deduping-at-scale/><link crossorigin=anonymous href=/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://tanayjha.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tanayjha.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tanayjha.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tanayjha.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tanayjha.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tanayjha.github.io/blog/deduping-at-scale/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Deduping at Scale"><meta property="og:description" content="Today I am going to talk about a project which I worked on in my organisation Sumo Logic.
We have this microservice which is used for collecting data from the cloud. One of the most prominent use case of that microservice is to collect data from customers S3 bucket.
I have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out here."><meta property="og:type" content="article"><meta property="og:url" content="https://tanayjha.github.io/blog/deduping-at-scale/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-11-29T12:09:25+05:30"><meta property="article:modified_time" content="2020-11-29T12:09:25+05:30"><meta name=twitter:card content="summary"><meta name=twitter:title content="Deduping at Scale"><meta name=twitter:description content="Today I am going to talk about a project which I worked on in my organisation Sumo Logic.
We have this microservice which is used for collecting data from the cloud. One of the most prominent use case of that microservice is to collect data from customers S3 bucket.
I have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out here."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://tanayjha.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Deduping at Scale","item":"https://tanayjha.github.io/blog/deduping-at-scale/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deduping at Scale","name":"Deduping at Scale","description":"Today I am going to talk about a project which I worked on in my organisation Sumo Logic.\nWe have this microservice which is used for collecting data from the cloud. One of the most prominent use case of that microservice is to collect data from customers S3 bucket.\nI have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out here.","keywords":[],"articleBody":"Today I am going to talk about a project which I worked on in my organisation Sumo Logic.\nWe have this microservice which is used for collecting data from the cloud. One of the most prominent use case of that microservice is to collect data from customers S3 bucket.\nI have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out here.\nAfter we solved the data discovery issue, we realised that there was another issue we were facing. This was limiting our scalability. The stakes this time were even higher.\nI can’t describe the complete architecture of the microservice as I would probably be violating some NDA. I will only talk about a small section of it which was the main bottleneck for us.\nContext We use the AWS List API to list the objects of the S3 bucket. Of course we take the necessary permissions from the customer to be able to do that. So we have a scanner thread running per source which lists the bucket.\nIn the blog I mentioned above, I discussed how we introduced another mechanism - SNS - to bring in the objects as well. So now every source can possibly have two methods of bringing in the data from S3 bucket:\nScanner\nSNS\nIn order to not duplicate the data coming in, we need some kind of dedupe mechanism in our microservice. (This was needed even before SNS was in picture, but lets not go into that application specific complexity right now)\nExisting Design We started off using a RDS (SQL DB) for deduping these S3 objects. So whenever an object came through Scanner or SNS, we first checked if it was present in the DB. If it was, that means we are fetching the object for the second time and we reject it.\nIf it is not present in the DB, we simply inserted it there.\nNow the DB table also maintained states of the object. So the object was initially inserted with a pending state. After that there was a poller running per node which fetched recent pending objects from the table and sent them downstream for further processing and updated their state to Completed.\nThis was the high level working of the initial part of the architecture.\nHere were the major issues with the existing design:\nNeeded a db.r5.4xlarge RDS instance (on our bigger deployments). There was a time when we had to run a db.r3.8xlarge machine since we had maxed out CPUs on the smaller ones. We didn’t have more room to scale vertically on a single DB.\nThere is a connection limit associated with the RDS instances which limited our horizontal scalability. With the db.r5.4xlarge instance that limit is 4000 connections. We give 40 connections to every node. So there is an upper limit of 100 nodes that we can add.\nAlthough we have bigger RDS instance size with us and we can scale vertically but there are two issues with that:\nMoving to a higher instance type effectively doubles the cost. The current one costs us about $40k/year\nAlthough moving to a higher instance size doubles the cost but it does not effectively double the number of connections. For eg. moving from 4xlarge -\u003e 8xlarge changes the connection from 4000 -\u003e 5000, so only 25 extra CC nodes capacity.\nHence we could not go too far with just vertical scalability. We need some way to create more headroom to allow horizontal scalability.\nAcceptance Criteria Acceptance criteria and goals of the new design:\nThe microservice on a big deployment handled 400 MB/sec with 20 nodes, keeping the cluster CPU at 50%. Every node gets 40 connections with the database. When one of our big customers were at their peak, the service was (barely) handling 1.2 GB/sec. The goal is to be able to handle 10x the current load. That is after the redesign, the service should be able to handle about 4GB/sec load.\nTry to solve the connection problem allowing more horizontal scalability. This is actually needed to achieve the above goal. The more nodes we are able to add, the more will be our processing power.\nTry to reduce the cost we currently incur for CC datastore. Maybe try and reduce the RDS instance size as some load will be shifted from it and moved to a key value store (which will have additional cost)\nApproaches Considered There were three major ways to revamp the design of this system:\nMove the design completely to use a NoSql store instead of RDS which would ensure better scalability and performance.\nMove some part of the system to a NoSql store and keep the remaining part on RDS.\nKeep all the data on RDS but shard the database for scalability.\nLet’s discuss each of these in detail listing down the pros and cons.\nCompletely move from RDS to a NoSql store So initially we thought of moving the SQL store to NoSQL completely. We knew that if a NoSql store fits our use case correctly, we can have a very scalable system built on top of it.\nWe decided to use DynamoDB and did a POC with it. For the most part it was looking impressive except that when we did a scale test, we hit something known as hot partitions. The reason for this was that one of our read queries (of fetching the most recent pending items) needed a GSI to be created on the dynamoDB table for it to be fast. The problem was that this GSI caused write throttling due to a hot key.\nNow there are ways to get around this problem. The most common one is write sharding. But it has it’s own set of challenges. We did complete the POC with this approach and it worked. However due to the involved complexity of write sharding, we decided to investigate further and see if we can find a better solution. Hence we kept this approach on hold.\nCompletely remain on the SQL store Now we knew that a single RDS instance was becoming a bottleneck for us. So what are the ways of scaling a SQL system?\nWell to support read heavy workloads, you use read replicas. And to support write heavy workloads, you shard your writer instance.\nNow we don’t use the reader instance of our DB. The reason is that we want strongly consistent reads. Since in a dedupe use case, if your reads are not strongly consistent, there is a possibility of data duplication. If you use a reader instance, you give up read after write consistency guarantees (due to the asynchronous replication). Hence we use the reader instance only as a failover.\nSo the next thought was to shard the database. Here is a nice blog on sharding. The more you read about it, the more you will realise that sharding is a bitter medicine which you should take only if there are no better options available. This article from Percona really puts that in perspective.\nApart from all the issues mentioned with sharding in the article above, another challenge specific to our organisation was that we did not have much experience with it. No other team had to do this before and there was no existing framework that we could leverage. Since we were running on a time crunch, hence we decided that it would probably be better to keep searching for an easier and more simple solution. That is what we did at least.\nMySql-NoSql Hybrid Approach The basic idea behind this approach was to separate the deduplication concerns with the rest of the input processing. The deduplication use case can be easily (and more cleanly) solved by a NoSql store.\nFirst let’s analyse what are the benefits we might get if we separate out deduplication from the rest: The existing architecture had a table which is used for Deduplication and persistence. What this table did was retain the input (read S3 object keys) for all the blades in the last 10 days. About 3 months back, there were about a billion entries in this table. This was causing a lot of issues for us (the main root cause was our purger not able to delete the entries at the correct pace). We eventually fixed the issue but even then there were about 400 million entries in the table. We run the getMostRecentObjects (mentioned above) query on this table. Even though it uses an index (and this was actually one of the issues above, the query was not using the correct index as the table size was so huge and the stats of the table were all skewed), this is probably not the best way to query for duplicates. If we move this to a NoSql store instead, we have the clear benefit of high performance. Also if we are able to move deduplication logic from RDS -\u003e NoSql, we would save on the database connections which are made to insert the objects in this Inputs table. We will have a separate table (which is present in the current design as well) which will handle the bookkeeping of thousands of concurrent inputs.\nHence it is easy to see that using a NoSql store for deduplication has its benefits.\nRollout Finally we decided to go with the MySql-NoSql hybrid approach. Another difficult aspect of this project was the rollout phase. There were three main phases in rollout:\nDual write on both old and new store. The new store had asynchronous retries to handle failures. We had metrics set up so that we have clear indication of the progress of this stage. After 10 days (our purging period), we could switch reads to the new store. After some time we can switch the writes as well to only the new store. Finally after 10 more days the old store would be empty and we can simply delete the SQL table. This was the connections graph in one of the production deployments after the rollout. We saw similar trends on all deployments i.e the connection usage became 1/3rd of the original value. This directly implied ~ 3X more horizontal scalability. (Obviously there is another factor of the DB CPU, but that was not too high to begin with)\nConclusion Overall this was a nice challenging project to work on and gave me a chance to work closely with some Sql/NoSql DBs. Database migration is a challenging task but if done right, it can really improve your scalability and save you the time and complexity of revamping your complete microservice!\n","wordCount":"1773","inLanguage":"en","datePublished":"2020-11-29T12:09:25+05:30","dateModified":"2020-11-29T12:09:25+05:30","mainEntityOfPage":{"@type":"WebPage","@id":"https://tanayjha.github.io/blog/deduping-at-scale/"},"publisher":{"@type":"Organization","name":"","logo":{"@type":"ImageObject","url":"https://tanayjha.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Deduping at Scale</h1><div class=post-meta>&lt;span title='2020-11-29 12:09:25 +0530 +0530'>November 29, 2020&lt;/span>&amp;nbsp;·&amp;nbsp;9 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#context aria-label=Context>Context</a></li><li><a href=#existing-design aria-label="Existing Design">Existing Design</a></li><li><a href=#acceptance-criteria aria-label="Acceptance Criteria">Acceptance Criteria</a></li><li><a href=#approaches-considered aria-label="Approaches Considered">Approaches Considered</a><ul><li><a href=#completely-move-from-rds-to-a-nosql-store aria-label="Completely move from RDS to a NoSql store">Completely move from RDS to a NoSql store</a></li><li><a href=#completely-remain-on-the-sql-store aria-label="Completely remain on the SQL store">Completely remain on the SQL store</a></li><li><a href=#mysql-nosql-hybrid-approach aria-label="MySql-NoSql Hybrid Approach">MySql-NoSql Hybrid Approach</a></li></ul></li><li><a href=#rollout aria-label=Rollout>Rollout</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></div></details></div><div class=post-content><p>Today I am going to talk about a project which I worked on in my organisation <a href=https://www.sumologic.com/>Sumo Logic</a>.</p><p>We have this microservice which is used for collecting data from the cloud. One of the most prominent <a href=https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/Amazon-Web-Services/AWS-S3-Source>use case</a> of that microservice is to collect data from customers S3 bucket.</p><p>I have written another blog on how we worked on making data discovery faster so that we can reduce ingestion lag. You can check it out <a href=https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/Amazon-Web-Services/AWS-S3-Source>here</a>.</p><p>After we solved the data discovery issue, we realised that there was another issue we were facing. This was limiting our scalability. The stakes this time were even higher.</p><p>I can&rsquo;t describe the complete architecture of the microservice as I would probably be violating some NDA. I will only talk about a small section of it which was the main bottleneck for us.</p><h3 id=context>Context<a hidden class=anchor aria-hidden=true href=#context>#</a></h3><p>We use the <a href=https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html>AWS List API</a> to list the objects of the S3 bucket. Of course we take the necessary permissions from the customer to be able to do that. So we have a scanner thread running per source which lists the bucket.</p><p>In the blog I mentioned above, I discussed how we introduced another mechanism - SNS - to bring in the objects as well. So now every source can possibly have two methods of bringing in the data from S3 bucket:</p><ol><li><p>Scanner</p></li><li><p>SNS</p></li></ol><p>In order to not duplicate the data coming in, we need some kind of dedupe mechanism in our microservice. (This was needed even before SNS was in picture, but lets not go into that application specific complexity right now)</p><h3 id=existing-design>Existing Design<a hidden class=anchor aria-hidden=true href=#existing-design>#</a></h3><p>We started off using a <a href=https://aws.amazon.com/rds/>RDS</a> (SQL DB) for deduping these S3 objects. So whenever an object came through Scanner or SNS, we first checked if it was present in the DB. If it was, that means we are fetching the object for the second time and we reject it.</p><p>If it is not present in the DB, we simply inserted it there.</p><p>Now the DB table also maintained states of the object. So the object was initially inserted with a pending state. After that there was a poller running per node which fetched recent pending objects from the table and sent them downstream for further processing and updated their state to Completed.</p><p>This was the high level working of the initial part of the architecture.</p><p>Here were the major issues with the existing design:</p><p>Needed a db.r5.4xlarge RDS instance (on our bigger deployments). There was a time when we had to run a db.r3.8xlarge machine since we had maxed out CPUs on the smaller ones. We didn’t have more room to scale vertically on a single DB.</p><p>There is a connection limit associated with the RDS instances which limited our horizontal scalability.
With the db.r5.4xlarge instance that limit is 4000 connections. We give 40 connections to every node. So there is an upper limit of 100 nodes that we can add.</p><p>Although we have bigger RDS instance size with us and we can scale vertically but there are two issues with that:</p><p>Moving to a higher instance type effectively doubles the cost. The current one costs us about $40k/year</p><p>Although moving to a higher instance size doubles the cost but it does not effectively double the
number of connections. For eg. moving from 4xlarge -> 8xlarge changes the connection from 4000 -> 5000,
so only 25 extra CC nodes capacity.</p><p>Hence we could not go too far with just vertical scalability. We need some way to create more headroom to allow horizontal scalability.</p><h3 id=acceptance-criteria>Acceptance Criteria<a hidden class=anchor aria-hidden=true href=#acceptance-criteria>#</a></h3><p>Acceptance criteria and goals of the new design:</p><p>The microservice on a big deployment handled 400 MB/sec with 20 nodes, keeping the cluster CPU at 50%. Every node gets 40 connections with the database. When one of our big customers were at their peak, the service was (barely) handling 1.2 GB/sec. The goal is to be able to handle 10x the current load. That is after the redesign, the service should be able to handle about 4GB/sec load.</p><p>Try to solve the connection problem allowing more horizontal scalability. This is actually needed to achieve the above goal. The more nodes we are able to add, the more will be our processing power.</p><p>Try to reduce the cost we currently incur for CC datastore. Maybe try and reduce the RDS instance size as some load will be shifted from it and moved to a key value store (which will have additional cost)</p><h3 id=approaches-considered>Approaches Considered<a hidden class=anchor aria-hidden=true href=#approaches-considered>#</a></h3><p>There were three major ways to revamp the design of this system:</p><p>Move the design completely to use a NoSql store instead of RDS which would ensure better scalability and performance.</p><p>Move some part of the system to a NoSql store and keep the remaining part on RDS.</p><p>Keep all the data on RDS but shard the database for scalability.</p><p>Let’s discuss each of these in detail listing down the pros and cons.</p><h4 id=completely-move-from-rds-to-a-nosql-store>Completely move from RDS to a NoSql store<a hidden class=anchor aria-hidden=true href=#completely-move-from-rds-to-a-nosql-store>#</a></h4><p>So initially we thought of moving the SQL store to NoSQL completely. We knew that if a NoSql store fits our use case correctly, we can have a very scalable system built on top of it.</p><p>We decided to use DynamoDB and did a POC with it. For the most part it was looking impressive except that when we did a scale test, we hit something known as hot partitions.
The reason for this was that one of our read queries (of fetching the most recent pending items) needed a GSI to be created on the dynamoDB table for it to be fast.
The problem was that this GSI caused write throttling due to a hot key.</p><figure><img loading=lazy src=/images/dedupe1.png></figure><p>Now there are ways to get around this problem. The most common one is write sharding. But it has it&rsquo;s own set of challenges. We did complete the POC with this approach and it worked. However due to the involved complexity of write sharding, we decided to investigate further and see if we can find a better solution. Hence we kept this approach on hold.</p><h4 id=completely-remain-on-the-sql-store>Completely remain on the SQL store<a hidden class=anchor aria-hidden=true href=#completely-remain-on-the-sql-store>#</a></h4><p>Now we knew that a single RDS instance was becoming a bottleneck for us. So what are the ways of scaling a SQL system?</p><p>Well to support read heavy workloads, you use read replicas.
And to support write heavy workloads, you shard your writer instance.</p><p>Now we don&rsquo;t use the reader instance of our DB. The reason is that we want strongly consistent reads. Since in a dedupe use case, if your reads are not strongly consistent, there is a possibility of data duplication. If you use a reader instance, you give up read after write consistency guarantees (due to the asynchronous replication). Hence we use the reader instance only as a failover.</p><p>So the next thought was to shard the database. Here is a nice blog on sharding.
The more you read about it, the more you will realise that sharding is a bitter medicine which you should take only if there are no better options available. This article from Percona really puts that in perspective.</p><p>Apart from all the issues mentioned with sharding in the article above, another challenge specific to our organisation was that we did not have much experience with it. No other team had to do this before and there was no existing framework that we could leverage.
Since we were running on a time crunch, hence we decided that it would probably be better to keep searching for an easier and more simple solution. That is what we did at least.</p><h4 id=mysql-nosql-hybrid-approach>MySql-NoSql Hybrid Approach<a hidden class=anchor aria-hidden=true href=#mysql-nosql-hybrid-approach>#</a></h4><p>The basic idea behind this approach was to separate the deduplication concerns with the rest of the input processing. The deduplication use case can be easily (and more cleanly) solved by a NoSql store.</p><p>First let’s analyse what are the benefits we might get if we separate out deduplication from the rest:
The existing architecture had a table which is used for Deduplication and persistence. What this table did was retain the input (read S3 object keys) for all the blades in the last 10 days. About 3 months back, there were about a billion entries in this table. This was causing a lot of issues for us (the main root cause was our purger not able to delete the entries at the correct pace). We eventually fixed the issue but even then there were about 400 million entries in the table.
We run the getMostRecentObjects (mentioned above) query on this table. Even though it uses an index (and this was actually one of the issues above, the query was not using the correct index as the table size was so huge and the stats of the table were all skewed), this is probably not the best way to query for duplicates. If we move this to a NoSql store instead, we have the clear benefit of high performance.
Also if we are able to move deduplication logic from RDS -> NoSql, we would save on the database connections which are made to insert the objects in this Inputs table. We will have a separate table (which is present in the current design as well) which will handle the bookkeeping of thousands of concurrent inputs.</p><p>Hence it is easy to see that using a NoSql store for deduplication has its benefits.</p><h3 id=rollout>Rollout<a hidden class=anchor aria-hidden=true href=#rollout>#</a></h3><p>Finally we decided to go with the MySql-NoSql hybrid approach. Another difficult aspect of this project was the rollout phase. There were three main phases in rollout:</p><ol><li>Dual write on both old and new store. The new store had asynchronous retries to handle failures. We had metrics set up so that we have clear indication of the progress of this stage.</li><li>After 10 days (our purging period), we could switch reads to the new store.</li><li>After some time we can switch the writes as well to only the new store.</li><li>Finally after 10 more days the old store would be empty and we can simply delete the SQL table.</li></ol><figure><img loading=lazy src=/images/dedupe2.png></figure><p>This was the connections graph in one of the production deployments after the rollout. We saw similar trends on all deployments i.e the connection usage became 1/3rd of the original value. This directly implied ~ 3X more horizontal scalability. (Obviously there is another factor of the DB CPU, but that was not too high to begin with)</p><h3 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h3><p>Overall this was a nice challenging project to work on and gave me a chance to work closely with some Sql/NoSql DBs. Database migration is a challenging task but if done right, it can really improve your scalability and save you the time and complexity of revamping your complete microservice!</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://tanayjha.github.io/></a></span><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>